---
title: "Bofan Chen QBS181 Project Code"
author: "Bofan Chen"
date: "2022-11-16"
output: pdf_document
---
## Description of Code
Thie file contains the detailed steps of tidyverse data cleaning and word cloud ploting for the variables team_home, team_away, statdium and stadium_address.


```{r setup, include=FALSE} 
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 
```


## Load the library

```{r cars}
if (!require("RColorBrewer")) {
  install.packages("RColorBrewer")
  library(RColorBrewer)
}
library(RColorBrewer)
# install.packages("wordcloud")
library(wordcloud)
library(SnowballC)
#install.packages("tm")
library(tm)
```

## Tidyverse Data Cleaning

```{r}

spreads <- read.csv("/Users/william/Library/Mobile Documents/com~apple~CloudDocs/QBS 181/spreadspoke_scores.csv")
stadiums <- read.csv("/Users/william/Library/Mobile Documents/com~apple~CloudDocs/QBS 181/nfl_stadiums.csv")
teams <- read.csv("/Users/william/Library/Mobile Documents/com~apple~CloudDocs/QBS 181/nfl_teams.csv")

summary(spreads)
summary(stadiums)
summary(teams)

library(tidyverse)


# Adding Abbreviations
df1 <- teams[,c("team_name", "team_id")]
df1 <- df1 %>% rename(team_home=team_name)
spread1 <- left_join(spreads, df1, by="team_home")

# Difference Favored
spread1$difference_favored_minus_notfavored <- ifelse(spread1$team_id == spread1$team_favorite_id, spread1$score_home-spread1$score_away, spread1$score_away-spread1$score_home)

# Comparing Spread
spread1$abs_spread <- abs(spread1$spread_favorite)
spread1$actual_diff_spread <- spread1$difference_favored_minus_notfavored - spread1$abs_spread

# Comparing Over Under
spread1$actual_total_over_under <- (spread1$score_home + spread1$score_away) - spread1$over_under_line

# Merge Stadiums
stadiums<- stadiums %>% rename(stadium=stadium_name)
merged_stadiums <- left_join(spread1, stadiums, by="stadium")

# Merge Teams
df2 <- teams[,c("team_name", "team_conference", "team_division", "team_conference_pre2002", "team_division_pre2002")]
df2 <- df2 %>% rename(team_home=team_name)
merged_teams <- left_join(merged_stadiums, df2, by="team_home")
```



## Visualize team_home

```{r pressure, echo=FALSE}
team_home <- merged_teams$team_home
team_home <- Corpus(VectorSource(team_home))
# Create a new blank canvas for word cloud plot
# dev.new(width = 2000, height = 2000, unit = "px")
# Word cloud plot
wordcloud(team_home
          , scale=c(5,0.5)     # Set min and max scale
          , max.words=100      # Set top n words
          , random.order=FALSE # Words in decreasing freq
          , rot.per=0.35       # % of vertical words
          , use.r.layout=FALSE # Use C++ collision detection
          , colors=brewer.pal(8, "Dark2"))
```

## Visualize team_stadium

```{r}
stadium <- read.csv("/Users/william/Library/Mobile Documents/com~apple~CloudDocs/QBS 181/stadium.csv")
# remove Stadium, Filed, Bowl, County, Memorial, Municipal, Coliseum, Dome, Superdome, Metrodome, Silverdome in Excel
stadium <- Corpus(VectorSource(stadium$stadium))


#dev.new(width = 2000, height = 2000, unit = "px")
wordcloud(stadium
          , scale=c(3.5,0.2)     # Set min and max scale
          , max.words=100      # Set top n words
          , random.order=FALSE # Words in decreasing freq
          , rot.per=0.15       # % of vertical words
          , use.r.layout=FALSE # Use C++ collision detection
          , colors=brewer.pal(8, "Dark2"))
```

# Visualize team_away

```{r}
team_away <- merged_teams$team_away
team_away <- Corpus(VectorSource(team_away))

#dev.new(width = 2000, height = 2000, unit = "px")
wordcloud(team_away
          , scale=c(5,0.5)     # Set min and max scale
          , max.words=100      # Set top n words
          , random.order=FALSE # Words in decreasing freq
          , rot.per=0.35       # % of vertical words
          , use.r.layout=FALSE # Use C++ collision detection
          , colors=brewer.pal(8, "Dark2"))
```

# Visualize stadium_address

```{r}
stadium_address <-  merged_teams$stadium_address
stadium_address <- Corpus(VectorSource(stadium_address))
# Convert to lowercase
# stadium_address <- tm_map(stadium_address, tolower)
# Remove conjunctions etc.
stadium_address <- tm_map(stadium_address, removeWords, stopwords("english"))
# Remove suffixes to the common 'stem'
stadium_address <- tm_map(stadium_address, stemDocument)
# Remove commas etc.
stadium_address <- tm_map(stadium_address, removePunctuation)

#dev.new(width = 2000, height = 2000, unit = "px")
wordcloud(stadium_address
          , scale=c(5,0.5)     # Set min and max scale
          , max.words=100      # Set top n words
          , random.order=FALSE # Words in decreasing freq
          , rot.per=0.35       # % of vertical words
          , use.r.layout=FALSE # Use C++ collision detection
          , colors=brewer.pal(8, "Dark2"))

```

